{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d50b9b5",
   "metadata": {},
   "source": [
    "# A Markov chain Monte Carlo (MCMC) Bayesian inference approach to analyze apparent activation barriers and reaction orders from microreactor data GUI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b78f8b9c",
   "metadata": {},
   "source": [
    "This script contains a GUI in which experimental data is imported as a CSV file and a Bayesian inference analysis is performed based on the model selected. The pooled model considers all experimental data points as one dataset, determines one linear regression model, and provides the 94% HDI.  The varying intercept and slope model will treat each catalyst bed as individual datasets and perform separate linear regressions. The varying intercept model will treat each catalyst bed as a separate dataset and calculate linear regression models for each with a constraint of each having the same slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8caced4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages for Bayesian inference, linear regression, and PySimpleGui\n",
    "\n",
    "# In your preferred conda environment, install the following Python packages for the Jupyter Notebook to work:\n",
    "# 1) PySimpleGui\n",
    "# 2) pymc\n",
    "# 3) sklearn\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import xarray as xr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebf7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for output figures to be of \"publishable\" quality for the linear regression plots\n",
    "\n",
    "def regression_plots():\n",
    "    az.style.use(\"default\")\n",
    "    params = {'axes.labelsize': 35,             # Default: 'medium'\n",
    "              'savefig.bbox': 'tight',\n",
    "              'figure.titlesize': 'large',      # Default: 'large'\n",
    "              'legend.fontsize': 15,            # Default: 'medium'\n",
    "              'lines.linewidth': 3,           # Default: 1.5\n",
    "              'lines.markersize': 15,           # Default: 6\n",
    "              'font.weight': 'normal',          # Default: 'normal'\n",
    "              'xtick.labelsize': 25,            # Default: 'medium'\n",
    "              'ytick.labelsize': 25,            # Default: 'medium'\n",
    "              'axes.linewidth': 3.5,            # Default: 0.8\n",
    "              'axes.labelweight': 'normal',     # Default: 'normal'\n",
    "    #           'font.family': 'Arial',           # Default: 'sans-serif'\n",
    "              'font.size': 5,                  # Default: 10\n",
    "              'legend.fancybox': False,\n",
    "              'legend.edgecolor': 'black',\n",
    "              'ytick.major.pad': 10,\n",
    "              'xtick.major.pad': 10,\n",
    "              'xtick.major.size': 10,            # Default: 3.5    \n",
    "              'xtick.major.width': 2,\n",
    "              'ytick.major.size': 10,\n",
    "              'ytick.major.width': 2\n",
    "             }\n",
    "\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f818af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for output figures to be of \"publishable\" quality for the traces of the MCMC\n",
    "\n",
    "def trace_plots():\n",
    "    %config InlineBackend.figure_format = 'retina'\n",
    "    az.style.use(\"arviz-darkgrid\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d83229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression analysis of the experimental data to obtain the mean for the priors of the slope and intercept\n",
    "\n",
    "def least_squares_regression(data):\n",
    "    data_numpy = data.to_numpy(copy=True)\n",
    "    \n",
    "    ln_P = data_numpy[:, 1]\n",
    "    ln_rate = data_numpy[:, 2]\n",
    "    \n",
    "    slope, intercept = np.polyfit(ln_P, ln_rate, 1)\n",
    "    \n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db16e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference with all experimental data as one dataset\n",
    "\n",
    "def complete_pooling(data, slope_mean, intercept_mean, slope_std, intercept_std, ln_rate_std, x_label, y_label):  \n",
    "    \n",
    "    columns = list(data.columns)\n",
    "    \n",
    "    trials, trial_number =data.trial.factorize()\n",
    "    \n",
    "    data_numpy = data.to_numpy(copy=True)\n",
    "    \n",
    "    ln_P_values = data_numpy[:,1]\n",
    "    ln_r_values = data_numpy[:,2]\n",
    "\n",
    "    with pm.Model() as pooled_model:\n",
    "        ln_P = pm.MutableData(x_label, ln_P_values, dims=\"obs_id\")\n",
    "        \n",
    "        # Priors\n",
    "        slope = pm.Normal(\"slope\", mu=slope_mean, sigma=np.abs(slope_std))\n",
    "        intercept = pm.Normal(\"intercept\", mu=intercept_mean, sigma=np.abs(intercept_std))\n",
    "        \n",
    "        # Likelihood\n",
    "        ln_r = slope * ln_P + intercept\n",
    "        \n",
    "        y = pm.Normal(y_label, ln_r, sigma=ln_rate_std, observed=ln_r_values, dims=\"obs_id\")\n",
    "        \n",
    "    with pooled_model:\n",
    "        step = pm.NUTS()\n",
    "        pooled_trace = pm.sample(step=step, tune=5000, draws=20000)\n",
    "        pm.sample_posterior_predictive(pooled_trace, extend_inferencedata=True)\n",
    "        \n",
    "    pooled_df = az.summary(pooled_trace, round_to=2)\n",
    "    headers = pooled_df.columns.to_list()[0:4]\n",
    "    headers.insert(0,\"\")\n",
    "    values = pooled_df.to_records().tolist()\n",
    "    \n",
    "    trace_plots()\n",
    "    \n",
    "    pooled_trace_plot = az.plot_trace(pooled_trace)\n",
    "    fig = pooled_trace_plot.ravel()[0].figure;\n",
    "    \n",
    "    # How to save PNGs to the same directory where this script is located\n",
    "    fig.savefig(\"complete_pooling_trace.png\")\n",
    "\n",
    "    post = pooled_trace.posterior\n",
    "    mu_pp = post[\"intercept\"] + post[\"slope\"] * xr.DataArray(ln_P_values, dims=[\"obs_id\"])\n",
    "    \n",
    "    regression_plots()\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    if intercept_mean > 0:\n",
    "        label_regression = \"%s = %0.2f * %s + %0.2f \" % (y_label, values[0][1], x_label, values[1][1])\n",
    "    else:\n",
    "        label_regression = \"%s = %0.2f * %s - %0.2f \" % (y_label, values[0][1], x_label, abs(values[1][1]))\n",
    "\n",
    "    ax.plot(ln_P_values, mu_pp.mean((\"chain\", \"draw\")), label=label_regression, color=\"C1\", alpha=0.6)\n",
    "\n",
    "    ax.scatter(ln_P_values, pooled_trace.observed_data[y_label], color='blue')\n",
    "    az.plot_hdi(ln_P_values, pooled_trace.posterior_predictive[y_label], hdi_prob=0.94)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(frameon=False, fontsize=20, bbox_to_anchor=(1, 1))\n",
    "    _.savefig(\"complete_pooling_hdi.png\")\n",
    "    \n",
    "    # Generating an output window containing a plot of the linear regression and a table of slope and intercept with their \n",
    "    # respective means, standard deviation, and 94% HDI's\n",
    "    col2 = [[sg.Image(\"complete_pooling_hdi.png\")],\n",
    "            [sg.Table(values=values, headings=headers, expand_x=True, justification='center', hide_vertical_scroll=True)]]\n",
    "    \n",
    "    layout2 = [[sg.Column(col2, scrollable=True, vertical_scroll_only=False, size=(1500,1500))]]\n",
    "\n",
    "    window2 = sg.Window(\"Complete Pooling\", layout2, finalize=True, resizable=True)\n",
    "    \n",
    "    # Generating another output window containing the trace of the MCMC\n",
    "    layout3 = [[sg.Image(\"complete_pooling_trace.png\")]]\n",
    "    \n",
    "    window3 = sg.Window(\"Complete Pooling Trace\", layout3, finalize=True)\n",
    "    \n",
    "    while True:\n",
    "        window4, event, values = sg.read_all_windows()\n",
    "        if event == sg.WIN_CLOSED or event==\"Exit\":\n",
    "            window4.close()\n",
    "            if window4 == window3:\n",
    "                window3 = None\n",
    "            elif window4 == window2:\n",
    "                break\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3fdfcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference constraining the slope\n",
    "\n",
    "def vary_intercept(data, slope_mean, intercept_mean, slope_std, intercept_std, ln_r_std, x_label, y_label):  \n",
    "   \n",
    "    columns = list(data.columns)\n",
    "    \n",
    "    trials, trial_number =data.trial.factorize()\n",
    "    \n",
    "    coords = {\"trials\": trial_number}\n",
    "    \n",
    "    data_numpy = data.to_numpy(copy=True)\n",
    "    \n",
    "    ln_P_values = data_numpy[:,1]\n",
    "    ln_r_values = data_numpy[:,2]\n",
    "    \n",
    "    with pm.Model(coords = coords) as vary_intercept_model:\n",
    "        ln_P = pm.MutableData(x_label, ln_P_values, dims=\"obs_id\")\n",
    "        trial_index = pm.MutableData(\"trial_index\", trials, dims=\"obs_id\")\n",
    "\n",
    "        # Priors \n",
    "        # Common Slope\n",
    "        slope = pm.Normal(\"slope\", mu=slope_mean, sigma=np.abs(slope_std))\n",
    "        # Random Intercepts\n",
    "        intercept = pm.Normal(\"intercept\", mu=intercept_mean, sigma=np.abs(intercept_std), dims=\"trials\")\n",
    "        \n",
    "        # Likelihood\n",
    "        ln_r = slope * ln_P + intercept[trial_index]\n",
    "        \n",
    "        y = pm.Normal(y_label, ln_r, sigma = ln_r_std, observed=ln_r_values, dims=\"obs_id\")\n",
    "        \n",
    "    with vary_intercept_model:\n",
    "        step = pm.NUTS()\n",
    "        vary_intercept_trace = pm.sample(step=step, tune=5000, draws=20000)\n",
    "        \n",
    "    vary_intercept_df = az.summary(vary_intercept_trace, round_to=2)\n",
    "    headers = vary_intercept_df.columns.to_list()[0:4]\n",
    "    headers.insert(0,\"\")\n",
    "    values = vary_intercept_df.to_records().tolist()\n",
    "    \n",
    "    trace_plots()\n",
    "    \n",
    "    vary_intercept_trace_plot = az.plot_trace(vary_intercept_trace, figsize=(12,7))\n",
    "    fig = vary_intercept_trace_plot.ravel()[0].figure\n",
    "    fig.savefig(\"vary_intercept_trace.png\")\n",
    "    \n",
    "    headers = vary_intercept_df.columns.to_list()[0:4]\n",
    "    headers.insert(0,\"\")\n",
    "    values = vary_intercept_df.to_records().tolist()\n",
    "    \n",
    "    post = vary_intercept_trace.posterior\n",
    "    mu_pp = post[\"intercept\"] + post[\"slope\"] * xr.DataArray(ln_P_values, dims=[\"obs_id\"])\n",
    "    \n",
    "    regression_plots()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    grouped_data = data.groupby(data.trial)\n",
    "    for trial in trial_number:\n",
    "        trial_data = grouped_data.get_group(trial)\n",
    "        columns = list(trial_data.columns)\n",
    "        ax.scatter(trial_data.iloc[:,1], trial_data.iloc[:,2])\n",
    "    for trial in trial_number:\n",
    "        trial_index = trial - 1\n",
    "        if intercept_mean > 0:\n",
    "            label_regression = \"%s = %0.2f * %s + %0.2f \" % (y_label, values[0][1], x_label, abs(values[trial][1]))\n",
    "        else:\n",
    "            label_regression = \"%s = %0.2f * %s - %0.2f \" % (y_label, values[0][1], x_label, abs(values[trial][1]))\n",
    "        ax.plot(ln_P_values, mu_pp.mean((\"chain\", \"draw\"))[trial_index], label = label_regression)\n",
    "    ax.legend(frameon=False, fontsize=20, bbox_to_anchor=(1, 1))\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    fig.savefig(\"vary_intercept_mean.png\")\n",
    "    \n",
    "    col5 = [[sg.Image(\"vary_intercept_mean.png\")],\n",
    "            [sg.Table(values=values, headings=headers, expand_x=True, justification='center', hide_vertical_scroll=True)]]\n",
    "    \n",
    "    layout5 = [[sg.Column(col5, scrollable=True, vertical_scroll_only=False, size=(1500,1500))]]\n",
    "    \n",
    "    window5 = sg.Window(\"Vary Intercept Model\", layout5, finalize=True, resizable=True)\n",
    "    \n",
    "    layout6 = [[sg.Image(\"vary_intercept_trace.png\")]]\n",
    "    \n",
    "    window6 = sg.Window(\"Vary Intercept Trace\", layout6, finalize=True)\n",
    "    \n",
    "    while True:\n",
    "        window7, event, values = sg.read_all_windows()\n",
    "        if event == sg.WIN_CLOSED or event==\"Exit\":\n",
    "            window7.close()\n",
    "            if window7 == window6:\n",
    "                window6=None\n",
    "            elif window7 == window5:\n",
    "                break\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4c5e51c-d5b4-425b-b0af-01924e30bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference for individual datasets\n",
    "\n",
    "def vary_intercept_slope(data, slope_mean, intercept_mean, slope_std, intercept_std, ln_r_std, x_label, y_label):  \n",
    "    print(slope_mean, intercept_mean, slope_std, intercept_std, ln_r_std)\n",
    "    \n",
    "    columns = list(data.columns)\n",
    "    \n",
    "    trials, trial_number =data.trial.factorize()\n",
    "    \n",
    "    coords = {\"trials\": trial_number}\n",
    "    \n",
    "    data_numpy = data.to_numpy(copy=True)\n",
    "    \n",
    "    ln_P_values = data_numpy[:,1]\n",
    "    ln_r_values = data_numpy[:,2]\n",
    "    \n",
    "    with pm.Model(coords = coords) as vary_intercept_slope_model:\n",
    "        ln_P = pm.MutableData(\"ln_P\", ln_P_values, dims=\"obs_id\")\n",
    "        trial_index = pm.MutableData(\"trial_index\", trials, dims=\"obs_id\")\n",
    "\n",
    "        \n",
    "        # Priors \n",
    "        # Random Slope\n",
    "        slope = pm.Normal(\"slope\", mu=slope_mean, sigma=slope_std, dims=\"trials\")\n",
    "        # Random Intercepts\n",
    "        intercept = pm.Normal(\"intercept\", mu=intercept_mean, sigma=np.abs(intercept_std), dims=\"trials\")\n",
    "        \n",
    "        # Likelihood\n",
    "        ln_r = slope[trial_index] * ln_P + intercept[trial_index]\n",
    "        \n",
    "        y = pm.Normal(\"ln_r\", ln_r, sigma = ln_r_std, observed=ln_r_values, dims=\"obs_id\")\n",
    "        \n",
    "    with vary_intercept_slope_model:\n",
    "#         step = pm.Metropolis()\n",
    "        vary_intercept_slope_trace = pm.sample()        \n",
    "    vary_intercept_slope_df = az.summary(vary_intercept_slope_trace, round_to=4)\n",
    "    headers = vary_intercept_slope_df.columns.to_list()[0:4]\n",
    "    headers.insert(0,\"\")\n",
    "    values = vary_intercept_slope_df.to_records().tolist()\n",
    "    \n",
    "    trace_plots()\n",
    "    \n",
    "    vary_intercept_slope_trace_plot = az.plot_trace(vary_intercept_slope_trace, figsize=(12,7))\n",
    "    fig = vary_intercept_slope_trace_plot.ravel()[0].figure\n",
    "    fig.savefig(\"vary_intercept_slope_trace.png\")\n",
    "\n",
    "    post = vary_intercept_slope_trace.posterior\n",
    "    mu_pp = post[\"intercept\"] + post[\"slope\"] * xr.DataArray(ln_P_values, dims=[\"obs_id\"])\n",
    "    \n",
    "    regression_plots()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    grouped_data = data.groupby(data.trial)\n",
    "    for trial in trial_number:\n",
    "        trial_data = grouped_data.get_group(trial)\n",
    "        columns = list(trial_data.columns)\n",
    "        ax.scatter(trial_data.iloc[:,1], trial_data.iloc[:,2])\n",
    "    for trial in trial_number:\n",
    "        trial_index = trial - 1\n",
    "        if intercept_mean > 0:\n",
    "            label_regression = \"%s = %0.2f * %s + %0.2f \" % (y_label, values[trial_index][1], x_label, abs(values[trial_index+4][1]))\n",
    "        else:\n",
    "            label_regression = \"%s = %0.2f * %s - %0.2f \" % (y_label, values[trial_index][1], x_label, abs(values[trial_index+4][1]))\n",
    "            \n",
    "        ax.plot(ln_P_values, mu_pp.mean((\"chain\", \"draw\"))[trial_index], label = label_regression)\n",
    "    ax.legend(frameon=False, fontsize=20, bbox_to_anchor=(1, 1))\n",
    "    ax.set_xlabel(\"ln(P)\")\n",
    "    ax.set_ylabel(\"ln(r)\")\n",
    "    fig.savefig(\"vary_intercept_slope_mean.png\")\n",
    "    \n",
    "    col4 = [[sg.Image(\"vary_intercept_slope_mean.png\")],\n",
    "            [sg.Table(values=values, headings=headers, expand_x=True, justification='center', hide_vertical_scroll=True)]]\n",
    "    \n",
    "    layout4 = [[sg.Column(col4, scrollable=True, vertical_scroll_only=False, size=(1500,1500))]]\n",
    "\n",
    "    \n",
    "    window4 = sg.Window(\"Vary Intercept and Slope Model\", layout4)\n",
    "\n",
    "    while True:\n",
    "        event, values = window4.read()\n",
    "        if event == sg.WIN_CLOSED or event==\"Exit\":\n",
    "            break\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fbc8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Layout for the input window\n",
    "\n",
    "layout = [[sg.Text(\"Choose formatted .CSV file containing the appropriate linear data to be modeled: \"), \n",
    "           sg.Input(key=\"-INPUT1-\"), \n",
    "           sg.FileBrowse(key=\"-IN1-\")],\n",
    "          [sg.Text(\"Enter label for the independent variable (x): \"), sg.Input(key=\"-INPUT2-\")],\n",
    "          [sg.Text(\"Enter label for the dependent variable (y): \"), sg.Input(key=\"-INPUT3-\")],\n",
    "          \n",
    "          [sg.T(\"\")],\n",
    "          \n",
    "          [sg.Text(\"Perform a Least Squares Regression analysis to obtain mean for the slope and intercept?\"), \n",
    "           # Divide question to provide std dev but calculating mean (default value?)\n",
    "           sg.Radio(\"Yes\", \"LSR\", key=\"-IN2-\", enable_events=True), \n",
    "           sg.Radio(\"No\", \"LSR\", key=\"-IN3-\", enable_events=True)],\n",
    "          \n",
    "          [sg.Text(size=(100,1), key=\"-OUTPUT1-\", text_color=\"yellow\")],\n",
    "          \n",
    "          [sg.Text(\"Provide standard deviations for the slope and intercept?\"),\n",
    "          sg.Radio(\"Yes\", \"StdDev\", key=\"-IN15-\", enable_events=True),\n",
    "          sg.Radio(\"No\", \"StdDev\", key=\"-IN16-\", enable_events=True)],\n",
    "          \n",
    "          [sg.Text(\"Standard deviations for slope and intercept are numerical parameters which will affect the 94% HDI\")],\n",
    "          \n",
    "          [sg.Text(size=(100,1), key='-OUTPUT2-', text_color=\"yellow\")],\n",
    "          \n",
    "#           [sg.T(\"\")],\n",
    "          \n",
    "          [sg.T(\"\"), sg.Push(), sg.Text(\"        \"), sg.Text(\"y\"),sg.Text(\"   \"), sg.Text(\"Slope\"), sg.Text(\"\"), sg.Text(\"Intercept\"), sg.Push()],\n",
    "          \n",
    "          [sg.Push(), sg.Text(\"Mean\"), sg.Text(\"              \"), sg.Input(size=(10,1), key=\"-IN7-\"), sg.Input(size=(10,1), key=\"-IN8-\"), sg.Push()],\n",
    "          \n",
    "          [sg.Push(), sg.Text(\"St. Dev.\"), sg.Input(size=(10,1), key=\"-IN9-\"), sg.Input(size=(10,1), key=\"-IN10-\"), sg.Input(size=(10,1), key=\"-IN11-\"), sg.Push()],\n",
    "          \n",
    "          [sg.Push(), sg.Text(\"Model to be Used:\"), sg.Radio(\"Pooled\", \"Model\", key=\"-IN12-\"), sg.Radio(\"Vary Intercept\", \"Model\", key=\"-IN13-\"), sg.Radio(\"Vary Intercept and Slope\", \"Model\", key=\"-IN14-\"), sg.Push()],\n",
    "#          [sg.Push(), sg.Text(\"Model to be Used:\"), sg.Radio(\"Pooled\", \"Model\", key=\"-IN12-\"), sg.Radio(\"Vary Intercept\", \"Model\", key=\"-IN13-\"), sg.Push()],\n",
    "\n",
    "                    \n",
    "          [sg.T(\"\")],\n",
    "                    \n",
    "          \n",
    "          [sg.Push(), sg.Button(\"Run\"), sg.Button(\"Exit\"), sg.Push()]\n",
    "                    \n",
    "         ]\n",
    "\n",
    "window = sg.Window(\"Bayesian GUI\", layout)\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event == sg.WIN_CLOSED or event==\"Exit\":\n",
    "        break\n",
    "        \n",
    "    if values[\"-IN3-\"] == True:\n",
    "        window[\"-OUTPUT1-\"].update(\"If no, you will be required to provide the mean for the slope and intercept.\")\n",
    "        window[\"-IN7-\"].update(disabled=False)\n",
    "        window[\"-IN8-\"].update(disabled=False)\n",
    "    elif (values[\"-IN2-\"] == True):\n",
    "        window[\"-OUTPUT1-\"].update(\"\")\n",
    "        window[\"-IN7-\"].update(disabled=True)\n",
    "        window[\"-IN8-\"].update(disabled=True)\n",
    "\n",
    "    if values[\"-IN15-\"] == True:\n",
    "        window[\"-OUTPUT2-\"].update(\"\")\n",
    "        window[\"-IN10-\"].update(disabled=False)\n",
    "        window[\"-IN11-\"].update(disabled=False)\n",
    "    elif values[\"-IN16-\"] == True:\n",
    "        window[\"-OUTPUT2-\"].update(\"If no, the standard deviation will be assumed to be 10% of the mean.\")\n",
    "        window[\"-IN10-\"].update(disabled=True)\n",
    "        window[\"-IN11-\"].update(disabled=True)\n",
    "        \n",
    "    if event == \"Run\":\n",
    "        data = pd.read_csv(values[\"-INPUT1-\"])\n",
    "        \n",
    "        ln_rate_std = float(values[\"-IN9-\"])\n",
    "        \n",
    "        if values[\"-IN2-\"] == True:\n",
    "            slope, intercept = least_squares_regression(data)\n",
    "        else:\n",
    "            slope = float(values[\"-IN7-\"])\n",
    "            intercept = float(values[\"-IN8-\"])            \n",
    "        \n",
    "        if values[\"-IN15-\"] == True:\n",
    "            slope_std = float(values[\"-IN10-\"])\n",
    "            intercept_std = float(values[\"-IN11-\"])\n",
    "        else:\n",
    "            slope_std = slope * 0.1\n",
    "            intercept_std = intercept * 0.1\n",
    "            \n",
    "        if values[\"-IN12-\"] == True:\n",
    "#             print(\"Complete Pooled Model\")\n",
    "            model = \"Complete\"\n",
    "            complete_pooling(data, slope, intercept, slope_std, intercept_std, ln_rate_std, values[\"-INPUT2-\"], values[\"-INPUT3-\"])       \n",
    "        elif values[\"-IN13-\"] == True:\n",
    "#             print(\"Vary Intercept Model\")\n",
    "            model = \"Vary Intercept\"\n",
    "            vary_intercept(data, slope, intercept, slope_std, intercept_std, ln_rate_std, values[\"-INPUT2-\"], values[\"-INPUT3-\"])\n",
    "        \n",
    "        elif values[\"-IN14-\"] == True:\n",
    "#            print(\"Vary Intercept and Slope Model\")\n",
    "            model = \"Vary Intercept Slope\"\n",
    "            vary_intercept_slope(data, slope, intercept, slope_std, intercept_std, ln_rate_std, values[\"-INPUT2-\"], values[\"-INPUT3-\"])\n",
    "        \n",
    "window.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
